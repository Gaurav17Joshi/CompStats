{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampling\n",
    "\n",
    "## Basic Implimenataion\n",
    "\n",
    "A particular Markov chain algorithm that has been found useful in many multidimensional problems is the Gibbs sampler, also called alternating conditional sampling, which is defined in terms of subvectors of $\\theta$.\n",
    "\n",
    "We first divide the parameter vector to its subvectors $\\theta = (\\theta_{1}, ... \\theta_{d})$.\n",
    "\n",
    "Each iteration of the Gibbs sampler cycles through the subvectors of $\\theta$, drawing each subset conditional on the value of all the others. There are thus $d$ steps in iteration $t$. At each iteration $t$, an ordering of the d subvectors of $\\theta$ is chosen and, in turn, each $\\theta_{j}^{t}$ is sampled from the conditional distribution given all the other components of $\\theta$\n",
    "\n",
    "$$\n",
    "p(\\theta_j | \\theta_{-j}^{t-1}, y)\n",
    "$$\n",
    "where $\\theta_{-j}^{t-1}$, represents all the components of $\\theta$ except for $\\theta_j$:\n",
    "\n",
    "$$\n",
    "\\theta_{-j}^{t-1} = (\\theta_{1}^{t}, \\theta_{2}^{t}, ... ,\\theta_{j-1}^{t}, \\theta_{j+1}^{t-1}, .... \\theta_{d}^{t-1})\n",
    "$$\n",
    "\n",
    "We sample out $\\theta_{j}$, conditioned on the value  of other parameters obtained up till now. It is quite useful in multidimensional cases, where the conditional distribution is easy to get.\n",
    "\n",
    "## Simple Example:-\n",
    "**Bivariate Normal Distribution**\n",
    "\n",
    "We will use the same example as in metropolis sampling example to check gibbs sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a simple implementation of Gibbs Sampling\n",
    "# Find gibbs equation for any multivariate normal distribution***\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of Gibbs Sampler\n",
    "\n",
    "Gibbs sampler seems to have a problem, the problem of getting the conditioned mean is indeed not straightforward in many case (eg: the example above), but we still make use of it as works much better than ordinary MCMC in High Dimensions.\n",
    "\n",
    "Why might that be the case??\n",
    "\n",
    "The reason being that in higher dimensions, the acceptance probability of proposals reduces exponentially. Think of it in general terms as if we are going away from the mode, the ratio of pdf values (or p), will we be say r in each direction, then the ratio becomes $r^d$ for d directions, hence reducing significantly. Whereas in Gibbs sampling we are updating the chain in one dimension at a time, hense we mitigate this problem of exponentially reducing acceptance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
